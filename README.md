# <h1 align="center">FeelChat</h1>
<p align="center"><img align="center" src="https://user-images.githubusercontent.com/33934387/194819986-35f28e15-9371-476a-a9ab-e4bc1f394215.png" width="12%" style="text-align: center"></p>


## Description
Project carried out as part of the *Mobile and Social Sensing Systems* Exam for the M.Sc. in Computer Engineering at the University of Pisa.

**FeelChat** is a Android app that features one to one chats with automatic emotion detection based from textual and audio data.

A brief presentation concerning technical challenges and results can be found [here](https://github.com/gerti98/MobileProject/blob/main/Presentation/Presentazione%20Finale-UPDATED.pptx).

## Tech Stack

 - *Android App*: Java
 - *Model training and deployment*: Tensorflow (Python) and Heroku
 - *Data Storage*: Firebase
 
## Screenshots

<div>
<img src="https://user-images.githubusercontent.com/33934387/206318334-21d711d1-0388-4a25-aaab-88fd45d5582a.png" width="150" />
<img src="https://user-images.githubusercontent.com/33934387/206318349-aa30fcd8-8d73-4be2-9187-ad7f91305216.png" width="150" />
<img src="https://user-images.githubusercontent.com/33934387/206318369-f5016df1-caa0-4b0a-a0fb-654dc96c1259.png" width="150" />
<img src="https://user-images.githubusercontent.com/33934387/206318391-4724ead7-999c-452b-8a25-89068a911f7a.png" width="150" />
<img src="https://user-images.githubusercontent.com/33934387/206318424-b226e554-493e-4d03-a0a0-d37e3de62016.png" width="150" />
</div>
